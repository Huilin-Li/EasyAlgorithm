{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split # only for split the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data (4 features, 3 classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_Length</th>\n",
       "      <th>Sepal_Width</th>\n",
       "      <th>Petal_Length</th>\n",
       "      <th>Petal_Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal_Length  Sepal_Width  Petal_Length  Petal_Width      Species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "col_names = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width','Species']\n",
    "iris_df =  pd.read_csv(csv_url, names = col_names)\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pre-processing: one_hot_encode for categorial data (labels in classification problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label  Iris-setosa  is represented by  [1, 0, 0]\n",
      "label  Iris-versicolor  is represented by  [0, 1, 0]\n",
      "label  Iris-virginica  is represented by  [0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "### Categorical data to be converted to numeric data\n",
    "labels = iris_df.Species.tolist()\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "### map each specise to an integer\n",
    "mapping = {}\n",
    "for x in range(len(unique_labels)):\n",
    "    mapping[unique_labels[x]] = x\n",
    "\n",
    "one_hot_encode = []\n",
    "\n",
    "for c in labels:\n",
    "    arr = list(np.zeros(len(unique_labels), dtype = int))\n",
    "    arr[mapping[c]] = 1\n",
    "    one_hot_encode.append(arr)\n",
    "    \n",
    "iris_df['act_arr'] = one_hot_encode\n",
    "print('label ', labels[0], ' is represented by ', one_hot_encode[0])\n",
    "print('label ', labels[90], ' is represented by ', one_hot_encode[90])\n",
    "print('label ', labels[-1], ' is represented by ', one_hot_encode[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_Length</th>\n",
       "      <th>Sepal_Width</th>\n",
       "      <th>Petal_Length</th>\n",
       "      <th>Petal_Width</th>\n",
       "      <th>Species</th>\n",
       "      <th>act_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal_Length  Sepal_Width  Petal_Length  Petal_Width         Species  \\\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa   \n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa   \n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa   \n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa   \n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa   \n",
       "..            ...          ...           ...          ...             ...   \n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica   \n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica   \n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica   \n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica   \n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica   \n",
       "\n",
       "       act_arr  \n",
       "0    [1, 0, 0]  \n",
       "1    [1, 0, 0]  \n",
       "2    [1, 0, 0]  \n",
       "3    [1, 0, 0]  \n",
       "4    [1, 0, 0]  \n",
       "..         ...  \n",
       "145  [0, 0, 1]  \n",
       "146  [0, 0, 1]  \n",
       "147  [0, 0, 1]  \n",
       "148  [0, 0, 1]  \n",
       "149  [0, 0, 1]  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df['act_arr'] = one_hot_encode\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This simple network has three layers (one input layer, one hidden layer with two nodes, one output layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 4\n",
    "n_labels = 3\n",
    "\n",
    "n_InputLayer = n_features\n",
    "n_HiddenLayer = 2 \n",
    "n_OutputLayer = n_labels\n",
    "\n",
    "np.random.seed(7)\n",
    "nnet_paras = {\n",
    "    'Ws_InputLayer_HiddenLayer': np.random.uniform(-(1/np.sqrt(n_InputLayer)), 1/np.sqrt(n_InputLayer), size=(n_InputLayer, n_HiddenLayer)) ,\n",
    "    'Bs_HiddenLayer': np.random.uniform(-(1/np.sqrt(n_HiddenLayer)), 1/np.sqrt(n_HiddenLayer), size=(n_HiddenLayer)),\n",
    "    'Ws_HiddenLayer_OutputLayer': np.random.uniform(-(1/np.sqrt(n_HiddenLayer)), 1/np.sqrt(n_HiddenLayer), size=(n_HiddenLayer, n_OutputLayer)),\n",
    "    'Bs_OutputLayer': np.random.uniform(-(1/np.sqrt(n_OutputLayer)), 1/np.sqrt(n_OutputLayer), size=(n_OutputLayer))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ws_InputLayer_HiddenLayer': array([[-0.42369171,  0.27991879],\n",
       "        [-0.06159077,  0.22346518],\n",
       "        [ 0.47798951,  0.03849587],\n",
       "        [ 0.00112046, -0.42794887]]),\n",
       " 'Bs_HiddenLayer': array([-3.27476735e-01, -1.66168926e-04]),\n",
       " 'Ws_HiddenLayer_OutputLayer': array([[ 0.25346949,  0.42955186, -0.16837466],\n",
       "        [-0.61385871, -0.29960737,  0.57925272]]),\n",
       " 'Bs_OutputLayer': array([-0.33095409, -0.05528249,  0.49791382])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial parameter values\n",
    "nnet_paras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation\n",
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function f in the hideen layer\n",
    "def sigmoid(input):\n",
    "    return 1 / (np.exp(-input) + 1)\n",
    "# activation function g in the output layer\n",
    "def softmax(inputs):\n",
    "    outputs = []\n",
    "    e_list = [np.exp(i) for i in inputs]\n",
    "    sum_e = sum(e_list)\n",
    "    for e in e_list:\n",
    "        tmp = e/sum_e\n",
    "        outputs.append(tmp)\n",
    "    return outputs\n",
    "# 'difference'\n",
    "def cross_entropy(pred_arr, act_arr):\n",
    "    idx = act_arr.argmax()\n",
    "    return -np.log(pred_arr[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, nnet_paras, act_arr):\n",
    "    nnet = {\n",
    "        'act_idx': [],\n",
    "        'pred':[],\n",
    "        'N_input':[],\n",
    "        'N_output':[],\n",
    "        'CE':[]\n",
    "    }\n",
    "    # get parameters\n",
    "    Ws_InputLayer_HiddenLayer = nnet_paras['Ws_InputLayer_HiddenLayer']\n",
    "    Bs_HiddenLayer = nnet_paras['Bs_HiddenLayer']\n",
    "    Ws_HiddenLayer_OutputLayer = nnet_paras['Ws_HiddenLayer_OutputLayer']\n",
    "    Bs_OutputLayer = nnet_paras['Bs_OutputLayer']\n",
    "    \n",
    "    # Hidden layer inputs\n",
    "    N_inputs = []\n",
    "    for w, b in zip(Ws_InputLayer_HiddenLayer.T, Bs_HiddenLayer):\n",
    "        N_input = sum(X*w) + b\n",
    "        N_inputs.append(N_input)\n",
    "        nnet['N_input'].append(N_input)\n",
    "    # Hidden layer outputs\n",
    "    N_outputs = [sigmoid(N_input) for N_input in N_inputs]\n",
    "    nnet['N_output'] = N_outputs\n",
    "    \n",
    "    # Outputlayer inputs\n",
    "    O_inputs = []\n",
    "    for w, b in zip(Ws_HiddenLayer_OutputLayer.T, Bs_OutputLayer):\n",
    "        O_input = sum(N_outputs*w) + b\n",
    "        O_inputs.append(O_input)\n",
    "    # Outputlayer outputs = Pred\n",
    "    O_outputs = softmax(O_inputs)\n",
    "    idx = np.argmax(act_arr)\n",
    "    nnet['act_idx'] = idx\n",
    "    nnet['pred'] = O_outputs\n",
    "    \n",
    "    # cross-entropy\n",
    "    CE = cross_entropy(O_outputs, np.array(act_arr))\n",
    "    nnet['CE'] = CE\n",
    "    \n",
    "    return nnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Propagation\n",
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_sample_total(idx_O, nnet_set):  \n",
    "    derivative = 0\n",
    "    for i in nnet_set:\n",
    "        nnet = nnet_set[i]\n",
    "        act_idx = nnet['act_idx']\n",
    "        pred = nnet['pred'][idx_O]\n",
    "        if act_idx == idx_O:\n",
    "            pred = pred - 1\n",
    "        derivative = derivative + pred\n",
    "    return derivative\n",
    "\n",
    "\n",
    "def pred_w_N_sample(idx_N, nnet, curr_para):\n",
    "    idx_O = nnet['act_idx']\n",
    "    pred_ = nnet['pred'][idx_O] - 1\n",
    "    w = curr_para['Ws_HiddenLayer_OutputLayer'][idx_N][idx_O]\n",
    "    N_input = nnet['N_input'][idx_N]\n",
    "    N = derivative_sigmoid(N_input) \n",
    "    return pred_*w*N\n",
    "\n",
    "\n",
    "def derivative_sigmoid(N_input):\n",
    "    f = 1/(1+np.exp(-N_input))\n",
    "    return f * (1 - f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(X_df, nnet_set, curr_para, lr):\n",
    "    n_InputLayer = len(curr_para['Ws_InputLayer_HiddenLayer'])\n",
    "    n_HiddenLayer = len(curr_para['Ws_HiddenLayer_OutputLayer']) \n",
    "    n_OutputLayer = len(curr_para['Bs_OutputLayer'])\n",
    "    \n",
    "    # adjust output layer b\n",
    "    new_Bs_OutputLayer = []\n",
    "    for O in range(n_OutputLayer):\n",
    "        derivative = pred_sample_total(O, nnet_set)\n",
    "        tmp = curr_para['Bs_OutputLayer'][O] - lr*derivative\n",
    "        new_Bs_OutputLayer.append(tmp)\n",
    "        \n",
    "    # adjust weights between hidden layer and output layer\n",
    "    new_Ws_HiddenLayer_OutputLayer = [] \n",
    "    for N in range(n_HiddenLayer):\n",
    "        hidden_outputlayer = []\n",
    "        for O in range(n_OutputLayer):\n",
    "            derivative = 0\n",
    "            for index,X in X_df.iterrows():\n",
    "                nnet = nnet_set[index]\n",
    "                N_output = nnet['N_output'][N]\n",
    "                idx_O = nnet['act_idx']\n",
    "                pred = nnet['pred'][idx_O]                \n",
    "                if idx_O == O:\n",
    "                    pred = pred - 1\n",
    "                derivative = derivative + pred*N_output\n",
    "            tmp = curr_para['Ws_HiddenLayer_OutputLayer'][N][O] - lr*derivative \n",
    "            hidden_outputlayer.append(tmp)\n",
    "        new_Ws_HiddenLayer_OutputLayer.append(hidden_outputlayer)\n",
    "    \n",
    "    \n",
    "    # adjust hidden layer b\n",
    "    new_Bs_HiddenLayer = []\n",
    "    for N in range(n_HiddenLayer):\n",
    "        derivative = 0\n",
    "        for index, X in X_df.iterrows():\n",
    "            nnet = nnet_set[index]\n",
    "            predwN = pred_w_N_sample(N, nnet, curr_para)\n",
    "            derivative = derivative + predwN\n",
    "        tmp = curr_para['Bs_HiddenLayer'][N] - lr*derivative\n",
    "        new_Bs_HiddenLayer.append(tmp)\n",
    "    \n",
    "    # adjust weights between input layer and hidden layer\n",
    "    new_Ws_InputLayer_HiddenLayer = []\n",
    "    for I in range(n_InputLayer):\n",
    "        inputlayer_HiddenLayer = []\n",
    "        for N in range(n_HiddenLayer):\n",
    "            derivative = 0\n",
    "            for index, X in X_df.iterrows():\n",
    "                nnet = nnet_set[index]\n",
    "                predwN = pred_w_N_sample(N, nnet, curr_para)\n",
    "                derivative = derivative + predwN*X[I]\n",
    "            tmp = curr_para['Ws_InputLayer_HiddenLayer'][I][N] - lr*derivative\n",
    "            inputlayer_HiddenLayer.append(tmp)\n",
    "        new_Ws_InputLayer_HiddenLayer.append(inputlayer_HiddenLayer)\n",
    "    # update\n",
    "    curr_para['Ws_InputLayer_HiddenLayer'] = np.array(new_Ws_InputLayer_HiddenLayer)\n",
    "    curr_para['Bs_HiddenLayer'] =  np.array(new_Bs_HiddenLayer)\n",
    "    curr_para['Ws_HiddenLayer_OutputLayer'] =  np.array(new_Ws_HiddenLayer_OutputLayer)\n",
    "    curr_para['Bs_OutputLayer'] =  np.array(new_Bs_OutputLayer) \n",
    "    \n",
    "    return curr_para"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training model to get the optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test dataset\n",
    "train, test = train_test_split(iris_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iter- 0 the loss is  174.64826862603908. At iter- 1 the loss is  155.31511415435367. At iter- 2 the loss is  144.34671509638758. At iter- 3 the loss is  138.77595924546227. At iter- 4 the loss is  135.78163001503387. At iter- 5 the loss is  133.92045294581467. At iter- 6 the loss is  132.6812689518622. At iter- 7 the loss is  131.8278587587348. At iter- 8 the loss is  131.21266701290023. At iter- 9 the loss is  130.73458633456124. At iter- 10 the loss is  130.3228345256791. At iter- 11 the loss is  129.9266409942647. At iter- 12 the loss is  129.5079674927264. At iter- 13 the loss is  129.03687974043476. At iter- 14 the loss is  128.4893906278874. At iter- 15 the loss is  127.84741147236431. At iter- 16 the loss is  127.09983659883709. At iter- 17 the loss is  126.24295794255255. At iter- 18 the loss is  125.27849787034599. At iter- 19 the loss is  124.20955788399786. At iter- 20 the loss is  123.03713749507432. At iter- 21 the loss is  121.75952540543716. At iter- 22 the loss is  120.37417749861838. At iter- 23 the loss is  118.88007819697084. At iter- 24 the loss is  117.27917713199099. At iter- 25 the loss is  115.57672300319967. At iter- 26 the loss is  113.78093024339175. At iter- 27 the loss is  111.90239498145036. At iter- 28 the loss is  109.95346191160385. At iter- 29 the loss is  107.9476080270485. At iter- 30 the loss is  105.89887329751095. At iter- 31 the loss is  103.8213651087426. At iter- 32 the loss is  101.72885748550708. At iter- 33 the loss is  99.6344963293799. At iter- 34 the loss is  97.55061340003482. At iter- 35 the loss is  95.48864773753151. At iter- 36 the loss is  93.45917559294892. At iter- 37 the loss is  91.47206131663691. At iter- 38 the loss is  89.5367682253551. At iter- 39 the loss is  87.66292646399425. At iter- 40 the loss is  85.86138853181617. At iter- 41 the loss is  84.14634174241891. At iter- 42 the loss is  82.54001098789952. At iter- 43 the loss is  81.08465252713081. At iter- 44 the loss is  79.87902420138106. At iter- 45 the loss is  79.21875840348505. At iter- 46 the loss is  80.31456402911282. At iter- 47 the loss is  87.98408795818558. At iter- 48 the loss is  86.81572351265145. At iter- 49 the loss is  82.04645644422486. At iter- 50 the loss is  78.95869968450464. At iter- 51 the loss is  76.52800769533158. At iter- 52 the loss is  74.50221120931751. At iter- 53 the loss is  72.76912678733545. At iter- 54 the loss is  71.25980652734064. At iter- 55 the loss is  69.92830448040365. At iter- 56 the loss is  68.74359827986353. At iter- 57 the loss is  67.68483326881662. At iter- 58 the loss is  66.73818798486583. At iter- 59 the loss is  65.89471042010798. At iter- 60 the loss is  65.14874382939925. At iter- 61 the loss is  64.49670423068724. At iter- 62 the loss is  63.936077287287056. At iter- 63 the loss is  63.464583580799804. At iter- 64 the loss is  63.07951675854989. At iter- 65 the loss is  62.77728378535207. At iter- 66 the loss is  62.553170719549684. At iter- 67 the loss is  62.401330638138475. At iter- 68 the loss is  62.31495829670443. At iter- 69 the loss is  62.286592669922285. At iter- 70 the loss is  62.30847993853193. At iter- 71 the loss is  62.37293484900001. At iter- 72 the loss is  62.472653203014694. At iter- 73 the loss is  62.600947305299854. At iter- 74 the loss is  62.7518947780619. At iter- 75 the loss is  62.920405819699326. At iter- 76 the loss is  63.10222318045929. At iter- 77 the loss is  63.2938730244475. At iter- 78 the loss is  63.49258470443949. At iter- 79 the loss is  63.696194886825985. "
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "max_iter = 80\n",
    "\n",
    "CE_total_list = []\n",
    "while iter < max_iter:    \n",
    "    # current net\n",
    "    nnet_set = {}\n",
    "    ### FORWARD\n",
    "    CE_total = 0\n",
    "    for index, row in train.iterrows():\n",
    "        X = row.iloc[:-2].tolist()\n",
    "        act_arr = row.iloc[-1]\n",
    "        nnet = forward(X, nnet_paras, act_arr)\n",
    "        CE_total = CE_total + nnet['CE']\n",
    "        \n",
    "        nnet_set[index] = nnet\n",
    "    print('At iter-', iter, 'the loss is ', CE_total, end='. ', flush=True)\n",
    "    CE_total_list.append(CE_total)\n",
    "    \n",
    "    ### BACKWARD\n",
    "    nnet_paras = backward(train, nnet_set, nnet_paras, lr=0.005)\n",
    "    \n",
    "    ####\n",
    "    iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(CE_total_list)\n",
    "\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ws_InputLayer_HiddenLayer': array([[-0.97310779, -0.86161539],\n",
       "        [-0.33077889, -1.16087308],\n",
       "        [ 0.06970534,  1.65688367],\n",
       "        [-0.14174733,  0.56760584]]),\n",
       " 'Bs_HiddenLayer': array([-0.41732183, -0.42186736]),\n",
       " 'Ws_HiddenLayer_OutputLayer': array([[-1.16924473, -1.29012472, -2.4057132 ],\n",
       "        [-7.53068762, -1.24876462,  1.65310123]]),\n",
       " 'Bs_OutputLayer': array([ 1.40097079,  0.0228037 , -1.31209723])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the optimal paramter values\n",
    "nnet_paras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The difference between the actual species and the predicted species is expected to decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test the adjusted model on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X, nnet_paras, mapping=mapping):\n",
    "    # get parameters\n",
    "    Ws_InputLayer_HiddenLayer = nnet_paras['Ws_InputLayer_HiddenLayer']\n",
    "    Bs_HiddenLayer = nnet_paras['Bs_HiddenLayer']\n",
    "    Ws_HiddenLayer_OutputLayer = nnet_paras['Ws_HiddenLayer_OutputLayer']\n",
    "    Bs_OutputLayer = nnet_paras['Bs_OutputLayer']\n",
    "    \n",
    "    # Hidden layer inputs\n",
    "    N_inputs = []\n",
    "    for w, b in zip(Ws_InputLayer_HiddenLayer.T, Bs_HiddenLayer):\n",
    "        N_input = sum(X*w) + b\n",
    "        N_inputs.append(N_input)\n",
    "        nnet['N_input'].append(N_input)\n",
    "    # Hidden layer outputs\n",
    "    N_outputs = [sigmoid(N_input) for N_input in N_inputs]\n",
    "    nnet['N_output'] = N_outputs\n",
    "    \n",
    "    # Outputlayer inputs\n",
    "    O_inputs = []\n",
    "    for w, b in zip(Ws_HiddenLayer_OutputLayer.T, Bs_OutputLayer):\n",
    "        O_input = sum(N_outputs*w) + b\n",
    "        O_inputs.append(O_input)\n",
    "    # Outputlayer outputs = Pred\n",
    "    O_outputs = softmax(O_inputs)\n",
    "    pred_idx = np.argmax(O_outputs)\n",
    "    # reverse the mapping\n",
    "    res = dict((v,k) for k,v in mapping.items())\n",
    "    \n",
    "    return res[pred_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_Length</th>\n",
       "      <th>Sepal_Width</th>\n",
       "      <th>Petal_Length</th>\n",
       "      <th>Petal_Width</th>\n",
       "      <th>Species</th>\n",
       "      <th>act_arr</th>\n",
       "      <th>pred_species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal_Length  Sepal_Width  Petal_Length  Petal_Width          Species  \\\n",
       "134           6.1          2.6           5.6          1.4   Iris-virginica   \n",
       "110           6.5          3.2           5.1          2.0   Iris-virginica   \n",
       "98            5.1          2.5           3.0          1.1  Iris-versicolor   \n",
       "32            5.2          4.1           1.5          0.1      Iris-setosa   \n",
       "55            5.7          2.8           4.5          1.3  Iris-versicolor   \n",
       "86            6.7          3.1           4.7          1.5  Iris-versicolor   \n",
       "140           6.7          3.1           5.6          2.4   Iris-virginica   \n",
       "126           6.2          2.8           4.8          1.8   Iris-virginica   \n",
       "85            6.0          3.4           4.5          1.6  Iris-versicolor   \n",
       "63            6.1          2.9           4.7          1.4  Iris-versicolor   \n",
       "149           5.9          3.0           5.1          1.8   Iris-virginica   \n",
       "80            5.5          2.4           3.8          1.1  Iris-versicolor   \n",
       "0             5.1          3.5           1.4          0.2      Iris-setosa   \n",
       "25            5.0          3.0           1.6          0.2      Iris-setosa   \n",
       "113           5.7          2.5           5.0          2.0   Iris-virginica   \n",
       "104           6.5          3.0           5.8          2.2   Iris-virginica   \n",
       "114           5.8          2.8           5.1          2.4   Iris-virginica   \n",
       "131           7.9          3.8           6.4          2.0   Iris-virginica   \n",
       "102           7.1          3.0           5.9          2.1   Iris-virginica   \n",
       "51            6.4          3.2           4.5          1.5  Iris-versicolor   \n",
       "136           6.3          3.4           5.6          2.4   Iris-virginica   \n",
       "84            5.4          3.0           4.5          1.5  Iris-versicolor   \n",
       "13            4.3          3.0           1.1          0.1      Iris-setosa   \n",
       "96            5.7          2.9           4.2          1.3  Iris-versicolor   \n",
       "143           6.8          3.2           5.9          2.3   Iris-virginica   \n",
       "66            5.6          3.0           4.5          1.5  Iris-versicolor   \n",
       "147           6.5          3.0           5.2          2.0   Iris-virginica   \n",
       "122           7.7          2.8           6.7          2.0   Iris-virginica   \n",
       "24            4.8          3.4           1.9          0.2      Iris-setosa   \n",
       "89            5.5          2.5           4.0          1.3  Iris-versicolor   \n",
       "\n",
       "       act_arr     pred_species  \n",
       "134  [0, 0, 1]   Iris-virginica  \n",
       "110  [0, 0, 1]   Iris-virginica  \n",
       "98   [0, 1, 0]      Iris-setosa  \n",
       "32   [1, 0, 0]      Iris-setosa  \n",
       "55   [0, 1, 0]  Iris-versicolor  \n",
       "86   [0, 1, 0]  Iris-versicolor  \n",
       "140  [0, 0, 1]   Iris-virginica  \n",
       "126  [0, 0, 1]   Iris-virginica  \n",
       "85   [0, 1, 0]  Iris-versicolor  \n",
       "63   [0, 1, 0]  Iris-versicolor  \n",
       "149  [0, 0, 1]   Iris-virginica  \n",
       "80   [0, 1, 0]  Iris-versicolor  \n",
       "0    [1, 0, 0]      Iris-setosa  \n",
       "25   [1, 0, 0]      Iris-setosa  \n",
       "113  [0, 0, 1]   Iris-virginica  \n",
       "104  [0, 0, 1]   Iris-virginica  \n",
       "114  [0, 0, 1]   Iris-virginica  \n",
       "131  [0, 0, 1]   Iris-virginica  \n",
       "102  [0, 0, 1]   Iris-virginica  \n",
       "51   [0, 1, 0]      Iris-setosa  \n",
       "136  [0, 0, 1]   Iris-virginica  \n",
       "84   [0, 1, 0]  Iris-versicolor  \n",
       "13   [1, 0, 0]      Iris-setosa  \n",
       "96   [0, 1, 0]  Iris-versicolor  \n",
       "143  [0, 0, 1]   Iris-virginica  \n",
       "66   [0, 1, 0]  Iris-versicolor  \n",
       "147  [0, 0, 1]   Iris-virginica  \n",
       "122  [0, 0, 1]   Iris-virginica  \n",
       "24   [1, 0, 0]      Iris-setosa  \n",
       "89   [0, 1, 0]  Iris-versicolor  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_species_test = []\n",
    "for index, row in test.iterrows():\n",
    "    X = row.iloc[:-2].tolist()\n",
    "    pred = prediction(X, nnet_paras)\n",
    "    pred_species_test.append(pred)\n",
    "\n",
    "test['pred_species'] = pred_species_test\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meaasure the accuracy of this trained model\n",
    "### measurement: \n",
    "$$\\text{Accuracy}=\\frac{\\text{Numbers of correct predictions}}{\\text{Numbers of total predictions made}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(act, pred):\n",
    "    correct_n = 0\n",
    "    for i, j in zip(act, pred):  \n",
    "        if i == j:\n",
    "            correct_n += 1\n",
    "    return correct_n/len(act)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act = test['Species']\n",
    "pred = test['pred_species']\n",
    "acc = Accuracy(act, pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This model can predict the species of the Iris flower with an accuracy of 93%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
