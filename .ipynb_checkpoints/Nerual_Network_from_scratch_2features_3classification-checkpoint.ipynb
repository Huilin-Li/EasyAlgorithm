{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split # only for split the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data (4 features, 3 classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_Length</th>\n",
       "      <th>Sepal_Width</th>\n",
       "      <th>Petal_Length</th>\n",
       "      <th>Petal_Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal_Length  Sepal_Width  Petal_Length  Petal_Width      Species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "col_names = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width','Species']\n",
    "iris_df =  pd.read_csv(csv_url, names = col_names)\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one_hot_encode for categorial data (labels in classification problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label  Iris-setosa  is represented by  [1, 0, 0]\n",
      "label  Iris-versicolor  is represented by  [0, 1, 0]\n",
      "label  Iris-virginica  is represented by  [0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "### Categorical data to be converted to numeric data\n",
    "labels = iris_df.Species.tolist()\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "### map each specise to an integer\n",
    "mapping = {}\n",
    "for x in range(len(unique_labels)):\n",
    "    mapping[unique_labels[x]] = x\n",
    "\n",
    "one_hot_encode = []\n",
    "\n",
    "for c in labels:\n",
    "    arr = list(np.zeros(len(unique_labels), dtype = int))\n",
    "    arr[mapping[c]] = 1\n",
    "    one_hot_encode.append(arr)\n",
    "    \n",
    "iris_df['act_arr'] = one_hot_encode\n",
    "print('label ', labels[0], ' is represented by ', one_hot_encode[0])\n",
    "print('label ', labels[90], ' is represented by ', one_hot_encode[90])\n",
    "print('label ', labels[-1], ' is represented by ', one_hot_encode[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_Length</th>\n",
       "      <th>Sepal_Width</th>\n",
       "      <th>Petal_Length</th>\n",
       "      <th>Petal_Width</th>\n",
       "      <th>Species</th>\n",
       "      <th>act_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal_Length  Sepal_Width  Petal_Length  Petal_Width         Species  \\\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa   \n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa   \n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa   \n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa   \n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa   \n",
       "..            ...          ...           ...          ...             ...   \n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica   \n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica   \n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica   \n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica   \n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica   \n",
       "\n",
       "       act_arr  \n",
       "0    [1, 0, 0]  \n",
       "1    [1, 0, 0]  \n",
       "2    [1, 0, 0]  \n",
       "3    [1, 0, 0]  \n",
       "4    [1, 0, 0]  \n",
       "..         ...  \n",
       "145  [0, 0, 1]  \n",
       "146  [0, 0, 1]  \n",
       "147  [0, 0, 1]  \n",
       "148  [0, 0, 1]  \n",
       "149  [0, 0, 1]  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df['act_arr'] = one_hot_encode\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation\n",
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function f in the hideen layer\n",
    "def sigmoid(input):\n",
    "    return 1 / (np.exp(-input) + 1)\n",
    "# activation function g in the output layer\n",
    "def softmax(inputs):\n",
    "    outputs = []\n",
    "    e_list = [np.exp(i) for i in inputs]\n",
    "    sum_e = sum(e_list)\n",
    "    for e in e_list:\n",
    "        tmp = e/sum_e\n",
    "        outputs.append(tmp)\n",
    "    return outputs\n",
    "# 'difference'\n",
    "def cross_entropy(pred_arr, act_arr):\n",
    "    idx = act_arr.argmax()\n",
    "    #print('cross-entropy:', idx)\n",
    "    #print('++++++++++:',pred_arr[idx])\n",
    "    return -np.log(pred_arr[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, nnet_paras, act_arr):\n",
    "    nnet = {\n",
    "        'act_idx': [],\n",
    "        'pred':[],\n",
    "        'N_input':[],\n",
    "        'N_output':[],\n",
    "        'CE':[]\n",
    "    }\n",
    "    # get parameters\n",
    "    Ws_InputLayer_HiddenLayer = nnet_paras['Ws_InputLayer_HiddenLayer']\n",
    "    Bs_HiddenLayer = nnet_paras['Bs_HiddenLayer']\n",
    "    Ws_HiddenLayer_OutputLayer = nnet_paras['Ws_HiddenLayer_OutputLayer']\n",
    "    Bs_OutputLayer = nnet_paras['Bs_OutputLayer']\n",
    "    \n",
    "    # Hidden layer inputs\n",
    "    N_inputs = []\n",
    "    for w, b in zip(Ws_InputLayer_HiddenLayer.T, Bs_HiddenLayer):\n",
    "        N_input = sum(X*w) + b\n",
    "        N_inputs.append(N_input)\n",
    "        nnet['N_input'].append(N_input)\n",
    "    # Hidden layer outputs\n",
    "    N_outputs = [sigmoid(N_input) for N_input in N_inputs]\n",
    "    nnet['N_output'] = N_outputs\n",
    "    \n",
    "    # Outputlayer inputs\n",
    "    O_inputs = []\n",
    "    for w, b in zip(Ws_HiddenLayer_OutputLayer.T, Bs_OutputLayer):\n",
    "        O_input = sum(N_outputs*w) + b\n",
    "        O_inputs.append(O_input)\n",
    "    # Outputlayer outputs = Pred\n",
    "    O_outputs = softmax(O_inputs)\n",
    "    idx = np.argmax(act_arr)\n",
    "    nnet['act_idx'] = idx\n",
    "    nnet['pred'] = O_outputs\n",
    "    \n",
    "    # cross-entropy\n",
    "    CE = cross_entropy(O_outputs, np.array(act_arr))\n",
    "    nnet['CE'] = CE\n",
    "    \n",
    "    return nnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Propagation\n",
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_sample_total(idx_O, nnet_set):  \n",
    "    derivative = 0\n",
    "    for i in nnet_set:\n",
    "        nnet = nnet_set[i]\n",
    "        act_idx = nnet['act_idx']\n",
    "        pred = nnet['pred'][idx_O]\n",
    "        if act_idx == idx_O:\n",
    "            pred = pred - 1\n",
    "        derivative = derivative + pred\n",
    "    return derivative\n",
    "\n",
    "\n",
    "def pred_w_N_sample(idx_N, nnet, curr_para):\n",
    "    idx_O = nnet['act_idx']\n",
    "    pred_ = nnet['pred'][idx_O] - 1\n",
    "    w = curr_para['Ws_HiddenLayer_OutputLayer'][idx_N][idx_O]\n",
    "    N_input = nnet['N_input'][idx_N]\n",
    "    N = derivative_sigmoid(N_input) \n",
    "    return pred_*w*N\n",
    "\n",
    "\n",
    "def derivative_sigmoid(N_input):\n",
    "    f = 1/(1+np.exp(-N_input))\n",
    "    return f * (1 - f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(X_df, nnet_set, curr_para, lr):\n",
    "    n_InputLayer = len(curr_para['Ws_InputLayer_HiddenLayer'])\n",
    "    n_HiddenLayer = len(curr_para['Ws_HiddenLayer_OutputLayer']) \n",
    "    n_OutputLayer = len(curr_para['Bs_OutputLayer'])\n",
    "    \n",
    "    # adjust output layer b\n",
    "    new_Bs_OutputLayer = []\n",
    "    for O in range(n_OutputLayer):\n",
    "        derivative = pred_sample_total(O, nnet_set)\n",
    "        tmp = curr_para['Bs_OutputLayer'][O] - lr*derivative\n",
    "        new_Bs_OutputLayer.append(tmp)\n",
    "        \n",
    "    # adjust weights between hidden layer and output layer\n",
    "    new_Ws_HiddenLayer_OutputLayer = [] \n",
    "    for N in range(n_HiddenLayer):\n",
    "        hidden_outputlayer = []\n",
    "        for O in range(n_OutputLayer):\n",
    "            derivative = 0\n",
    "            for index,X in X_df.iterrows():\n",
    "                nnet = nnet_set[index]\n",
    "                N_output = nnet['N_output'][N]\n",
    "                idx_O = nnet['act_idx']\n",
    "                pred = nnet['pred'][idx_O]                \n",
    "                if idx_O == O:\n",
    "                    pred = pred - 1\n",
    "                derivative = derivative + pred*N_output\n",
    "            tmp = curr_para['Ws_HiddenLayer_OutputLayer'][N][O] - lr*derivative \n",
    "            hidden_outputlayer.append(tmp)\n",
    "        new_Ws_HiddenLayer_OutputLayer.append(hidden_outputlayer)\n",
    "    \n",
    "    \n",
    "    # adjust hidden layer b\n",
    "    new_Bs_HiddenLayer = []\n",
    "    for N in range(n_HiddenLayer):\n",
    "        derivative = 0\n",
    "        for index, X in X_df.iterrows():\n",
    "            nnet = nnet_set[index]\n",
    "            predwN = pred_w_N_sample(N, nnet, curr_para)\n",
    "            derivative = derivative + predwN\n",
    "        tmp = curr_para['Bs_HiddenLayer'][N] - lr*derivative\n",
    "        new_Bs_HiddenLayer.append(tmp)\n",
    "    \n",
    "    # adjust weights between input layer and hidden layer\n",
    "    new_Ws_InputLayer_HiddenLayer = []\n",
    "    for I in range(n_InputLayer):\n",
    "        inputlayer_HiddenLayer = []\n",
    "        for N in range(n_HiddenLayer):\n",
    "            derivative = 0\n",
    "            for index, X in X_df.iterrows():\n",
    "                nnet = nnet_set[index]\n",
    "                predwN = pred_w_N_sample(N, nnet, curr_para)\n",
    "                derivative = derivative + predwN*X[I]\n",
    "            tmp = curr_para['Ws_InputLayer_HiddenLayer'][I][N] - lr*derivative\n",
    "            inputlayer_HiddenLayer.append(tmp)\n",
    "        new_Ws_InputLayer_HiddenLayer.append(inputlayer_HiddenLayer)\n",
    "    # update\n",
    "    curr_para['Ws_InputLayer_HiddenLayer'] = np.array(new_Ws_InputLayer_HiddenLayer)\n",
    "    curr_para['Bs_HiddenLayer'] =  np.array(new_Bs_HiddenLayer)\n",
    "    curr_para['Ws_HiddenLayer_OutputLayer'] =  np.array(new_Ws_HiddenLayer_OutputLayer)\n",
    "    curr_para['Bs_OutputLayer'] =  np.array(new_Bs_OutputLayer[0]) \n",
    "    \n",
    "    return curr_para"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_Length</th>\n",
       "      <th>Sepal_Width</th>\n",
       "      <th>Petal_Length</th>\n",
       "      <th>Petal_Width</th>\n",
       "      <th>Species</th>\n",
       "      <th>act_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal_Length  Sepal_Width  Petal_Length  Petal_Width          Species  \\\n",
       "144           6.7          3.3           5.7          2.5   Iris-virginica   \n",
       "129           7.2          3.0           5.8          1.6   Iris-virginica   \n",
       "85            6.0          3.4           4.5          1.6  Iris-versicolor   \n",
       "53            5.5          2.3           4.0          1.3  Iris-versicolor   \n",
       "101           5.8          2.7           5.1          1.9   Iris-virginica   \n",
       "..            ...          ...           ...          ...              ...   \n",
       "147           6.5          3.0           5.2          2.0   Iris-virginica   \n",
       "70            5.9          3.2           4.8          1.8  Iris-versicolor   \n",
       "74            6.4          2.9           4.3          1.3  Iris-versicolor   \n",
       "102           7.1          3.0           5.9          2.1   Iris-virginica   \n",
       "52            6.9          3.1           4.9          1.5  Iris-versicolor   \n",
       "\n",
       "       act_arr  \n",
       "144  [0, 0, 1]  \n",
       "129  [0, 0, 1]  \n",
       "85   [0, 1, 0]  \n",
       "53   [0, 1, 0]  \n",
       "101  [0, 0, 1]  \n",
       "..         ...  \n",
       "147  [0, 0, 1]  \n",
       "70   [0, 1, 0]  \n",
       "74   [0, 1, 0]  \n",
       "102  [0, 0, 1]  \n",
       "52   [0, 1, 0]  \n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "col_names = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width','Species']\n",
    "iris_df =  pd.read_csv(csv_url, names = col_names)\n",
    "\n",
    "labels = iris_df.Species.tolist()\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "### map each color to an integer\n",
    "mapping = {}\n",
    "for x in range(len(unique_labels)):\n",
    "    mapping[unique_labels[x]] = x\n",
    "\n",
    "one_hot_encode = []\n",
    "\n",
    "for c in labels:\n",
    "    arr = list(np.zeros(len(unique_labels), dtype = int))\n",
    "    arr[mapping[c]] = 1\n",
    "    one_hot_encode.append(arr)\n",
    "    \n",
    "iris_df['act_arr'] = one_hot_encode\n",
    "train, test = train_test_split(iris_df, test_size=0.2)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 4\n",
    "n_labels = 3\n",
    "\n",
    "n_InputLayer = n_features\n",
    "n_HiddenLayer = 2 \n",
    "n_OutputLayer = n_labels\n",
    "\n",
    "np.random.seed(7)\n",
    "nnet_paras = {\n",
    "    'Ws_InputLayer_HiddenLayer': np.random.uniform(-(1/np.sqrt(n_InputLayer)), 1/np.sqrt(n_InputLayer), size=(n_InputLayer, n_HiddenLayer)) ,\n",
    "    'Bs_HiddenLayer': np.random.uniform(-(1/np.sqrt(n_HiddenLayer)), 1/np.sqrt(n_HiddenLayer), size=(n_HiddenLayer)),\n",
    "    'Ws_HiddenLayer_OutputLayer': np.random.uniform(-(1/np.sqrt(n_HiddenLayer)), 1/np.sqrt(n_HiddenLayer), size=(n_HiddenLayer, n_OutputLayer)),\n",
    "    'Bs_OutputLayer': np.random.uniform(-(1/np.sqrt(n_OutputLayer)), 1/np.sqrt(n_OutputLayer), size=(n_OutputLayer))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ws_InputLayer_HiddenLayer': array([[-0.42369171,  0.27991879],\n",
      "       [-0.06159077,  0.22346518],\n",
      "       [ 0.47798951,  0.03849587],\n",
      "       [ 0.00112046, -0.42794887]]), 'Bs_HiddenLayer': array([-3.27476735e-01, -1.66168926e-04]), 'Ws_HiddenLayer_OutputLayer': array([[ 0.25346949,  0.42955186, -0.16837466],\n",
      "       [-0.61385871, -0.29960737,  0.57925272]]), 'Bs_OutputLayer': array([-0.33095409, -0.05528249,  0.49791382])}\n"
     ]
    }
   ],
   "source": [
    "print(nnet_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter at: 0\n",
      "CE total: 163.03664656216307\n",
      "========================\n",
      "iter at: 1\n",
      "CE total: 154.60861264681785\n",
      "========================\n",
      "iter at: 2\n",
      "CE total: 147.33400313198476\n",
      "========================\n",
      "iter at: 3\n",
      "CE total: 141.65146900029998\n",
      "========================\n",
      "iter at: 4\n",
      "CE total: 139.3884182812335\n",
      "========================\n",
      "iter at: 5\n",
      "CE total: 139.2856324301919\n",
      "========================\n",
      "iter at: 6\n",
      "CE total: 138.95914340619586\n",
      "========================\n",
      "iter at: 7\n",
      "CE total: 136.85559012946604\n",
      "========================\n",
      "iter at: 8\n",
      "CE total: 133.62328867998488\n",
      "========================\n",
      "iter at: 9\n",
      "CE total: 132.13858131041908\n",
      "========================\n",
      "iter at: 10\n",
      "CE total: 130.36621697577172\n",
      "========================\n",
      "iter at: 11\n",
      "CE total: 128.82848244788227\n",
      "========================\n",
      "iter at: 12\n",
      "CE total: 127.12143586659674\n",
      "========================\n",
      "iter at: 13\n",
      "CE total: 125.98199551196784\n",
      "========================\n",
      "iter at: 14\n",
      "CE total: 124.47827739594199\n",
      "========================\n",
      "iter at: 15\n",
      "CE total: 124.13715532725176\n",
      "========================\n",
      "iter at: 16\n",
      "CE total: 122.66084954186083\n",
      "========================\n",
      "iter at: 17\n",
      "CE total: 123.3481106127878\n",
      "========================\n",
      "iter at: 18\n",
      "CE total: 121.6599959483386\n",
      "========================\n",
      "iter at: 19\n",
      "CE total: 123.09955575754216\n",
      "========================\n",
      "iter at: 20\n",
      "CE total: 121.54710797480976\n",
      "========================\n",
      "iter at: 21\n",
      "CE total: 122.89810970820723\n",
      "========================\n",
      "iter at: 22\n",
      "CE total: 122.20746126215963\n",
      "========================\n",
      "iter at: 23\n",
      "CE total: 122.76671637510142\n",
      "========================\n",
      "iter at: 24\n",
      "CE total: 122.58605687722917\n",
      "========================\n",
      "iter at: 25\n",
      "CE total: 122.2135375988439\n",
      "========================\n",
      "iter at: 26\n",
      "CE total: 121.22727452069748\n",
      "========================\n",
      "iter at: 27\n",
      "CE total: 120.04334630199969\n",
      "========================\n",
      "iter at: 28\n",
      "CE total: 119.80655380945024\n",
      "========================\n",
      "iter at: 29\n",
      "CE total: 120.29324601072716\n",
      "========================\n",
      "iter at: 30\n",
      "CE total: 120.8708688809128\n",
      "========================\n",
      "iter at: 31\n",
      "CE total: 121.40571080183591\n",
      "========================\n",
      "iter at: 32\n",
      "CE total: 121.87145332730866\n",
      "========================\n",
      "iter at: 33\n",
      "CE total: 122.27104776578962\n",
      "========================\n",
      "iter at: 34\n",
      "CE total: 122.61319180520724\n",
      "========================\n",
      "iter at: 35\n",
      "CE total: 122.90687100957712\n",
      "========================\n",
      "iter at: 36\n",
      "CE total: 123.1599439271799\n",
      "========================\n",
      "iter at: 37\n",
      "CE total: 123.3789436853343\n",
      "========================\n",
      "iter at: 38\n",
      "CE total: 123.56921459416525\n",
      "========================\n",
      "iter at: 39\n",
      "CE total: 123.73511617725649\n",
      "========================\n",
      "iter at: 40\n",
      "CE total: 123.88021492924676\n",
      "========================\n",
      "iter at: 41\n",
      "CE total: 124.0074443537937\n",
      "========================\n",
      "iter at: 42\n",
      "CE total: 124.11923284707173\n",
      "========================\n",
      "iter at: 43\n",
      "CE total: 124.21760423531524\n",
      "========================\n",
      "iter at: 44\n",
      "CE total: 124.30425647004655\n",
      "========================\n",
      "iter at: 45\n",
      "CE total: 124.3806233132986\n",
      "========================\n",
      "iter at: 46\n",
      "CE total: 124.44792289855545\n",
      "========================\n",
      "iter at: 47\n",
      "CE total: 124.5071961805912\n",
      "========================\n",
      "iter at: 48\n",
      "CE total: 124.55933757570894\n",
      "========================\n",
      "iter at: 49\n",
      "CE total: 124.6051195416395\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "max_iter = 50\n",
    "\n",
    "\n",
    "CE_total_list = []\n",
    "while iter < max_iter:\n",
    "    print('iter at:', iter)\n",
    "    # current net\n",
    "    nnet_set = {}\n",
    "    ### FORWARD\n",
    "    CE_total = 0\n",
    "    for index, row in train.iterrows():\n",
    "        X = row.iloc[:-2].tolist()\n",
    "        act_arr = row.iloc[-1]\n",
    "        nnet = forward(X, nnet_paras, act_arr)\n",
    "        CE_total = CE_total + nnet['CE']\n",
    "        \n",
    "        nnet_set[index] = nnet\n",
    "    print('CE total:', CE_total)\n",
    "    CE_total_list.append(CE_total)\n",
    "    \n",
    "    ### BACKWARD\n",
    "    nnet_paras = backward(train, nnet_set, nnet_paras, lr=0.01)\n",
    "    \n",
    "    ####\n",
    "    iter += 1\n",
    "    print('========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(CE_total_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
